Ensemble methods are done by two ways:

Bagging : 
Learn by majority vote.
Take different models predictor like decision trees and average the prediction.
It is done in a parallel way.



Models: Random Forest





Boosting : 
Learn by the weak learners in a sequential way.



Models; XGBoost, Ada, LightGBM, Catboost.